{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已生成 100/2000 张图像\n",
      "已生成 200/2000 张图像\n",
      "已生成 300/2000 张图像\n",
      "已生成 400/2000 张图像\n",
      "已生成 500/2000 张图像\n",
      "已生成 600/2000 张图像\n",
      "已生成 700/2000 张图像\n",
      "已生成 800/2000 张图像\n",
      "已生成 900/2000 张图像\n",
      "已生成 1000/2000 张图像\n",
      "已生成 1100/2000 张图像\n",
      "已生成 1200/2000 张图像\n",
      "已生成 1300/2000 张图像\n",
      "已生成 1400/2000 张图像\n",
      "已生成 1500/2000 张图像\n",
      "已生成 1600/2000 张图像\n",
      "已生成 1700/2000 张图像\n",
      "已生成 1800/2000 张图像\n",
      "已生成 1900/2000 张图像\n",
      "已生成 2000/2000 张图像\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generate_mnist_combinations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 132\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m已生成 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/2000 张图像\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[43mgenerate_mnist_combinations\u001b[49m()\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m所有图像生成完成！\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_mnist_combinations' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import struct\n",
    "from tqdm import trange\n",
    "# 设置随机种子以确保结果可重现\n",
    "random.seed(42)\n",
    "\n",
    "# 配置数据保存路径\n",
    "output_dir = '/cpfs04/user/hanyujin/rule-gen/datasets/mnist-mnist/images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 加载MNIST数据集\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # 确保图像是28x28的\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, images_path, labels_path, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.labels_path = labels_path\n",
    "        self.transform = transform\n",
    "\n",
    "        # 加载图片和标签\n",
    "        self.images = self._load_images(self.images_path)\n",
    "        self.labels = self._load_labels(self.labels_path)\n",
    "\n",
    "    def _load_images(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            # Skip the first 16 bytes of the magic number and dimensions info\n",
    "            f.read(16)\n",
    "            # 读取所有图片数据\n",
    "            data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            images = data.reshape(-1, 28, 28)  # 图片是28x28的\n",
    "        return images\n",
    "\n",
    "    def _load_labels(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            # Skip the first 8 bytes of the magic number and number of labels\n",
    "            f.read(8)\n",
    "            labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = Image.fromarray(image)  # 将图片从numpy数组转为PIL图像\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 配置转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # 确保图像是28x28的\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 数据路径\n",
    "train_images_path = '/cpfs04/user/hanyujin/rule-gen/datasets/MNIST/raw/train-images-idx3-ubyte'\n",
    "train_labels_path = '/cpfs04/user/hanyujin/rule-gen/datasets/MNIST/raw/train-labels-idx1-ubyte'\n",
    "\n",
    "# 加载数据\n",
    "train_dataset = MNISTDataset(train_images_path, train_labels_path, transform=transform)\n",
    "\n",
    "\n",
    "digit_images = defaultdict(list)\n",
    "for img, label in train_dataset:\n",
    "    digit_images[label.item()].append(img)\n",
    "\n",
    "# 生成所有有效的三元组组合\n",
    "valid_triples = []\n",
    "for a in range(0, 10):\n",
    "    for b in range(a, 10):\n",
    "        for c in range(b, 10):\n",
    "            if 15 <= (a + b + c) <= 24:\n",
    "                valid_triples.append((a, b, c))\n",
    "\n",
    "# 生成2000张合成图像\n",
    "for idx in range(2000):\n",
    "    while True:\n",
    "        # 随机选择有效三元组并打乱顺序\n",
    "        a, b, c = random.choice(valid_triples)\n",
    "        nums = random.sample([a, b, c], 3)\n",
    "        s = sum(nums)\n",
    "        d = 24 - s\n",
    "\n",
    "        # 确保所有数字都有可用图像\n",
    "        if all(len(digit_images[n]) > 0 for n in nums + [d]):\n",
    "            break\n",
    "\n",
    "    # 随机选择图像\n",
    "    img1 = random.choice(digit_images[nums[0]])\n",
    "    img2 = random.choice(digit_images[nums[1]])\n",
    "    img3 = random.choice(digit_images[nums[2]])\n",
    "    img4 = random.choice(digit_images[d])\n",
    "\n",
    "    # 转换并调整图像大小\n",
    "    def process_img(img_tensor):\n",
    "        img = to_pil_image(img_tensor).resize((32, 32), Image.LANCZOS)\n",
    "        return img.convert('L')  # 确保灰度模式\n",
    "\n",
    "    # 合成64x64图像\n",
    "    canvas = Image.new('L', (64, 64), color=255)\n",
    "    canvas.paste(process_img(img1), (0, 0))    # 左上\n",
    "    canvas.paste(process_img(img2), (32, 0))   # 右上\n",
    "    canvas.paste(process_img(img3), (0, 32))  # 左下\n",
    "    canvas.paste(process_img(img4), (32, 32)) # 右下\n",
    "\n",
    "    # 保存图像\n",
    "    canvas.save(os.path.join(output_dir, f'combined_{idx:04d}.png'))\n",
    "\n",
    "    # 打印进度\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        print(f'已生成 {idx + 1}/2000 张图像')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "# -------------------- 设备配置 --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "mnist_classes = [str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- MNIST模型定义 --------------------\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 输入: 1x28x28\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # 输入通道改为1\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 输出: 32x14x14\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 输出: 64x7x7\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1)  # 全局平均池化输出: 128x1x1\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(report):\n",
    "    total_samples = sum(v[\"samples\"] for v in report.values())\n",
    "    total_correct = sum(int(v[\"accuracy\"]*v[\"samples\"]) for v in report.values())\n",
    "    \n",
    "    print(\"\\n{:<30} {:<10} {:<10}\".format(\"Folder\", \"Accuracy\", \"Samples\"))\n",
    "    print(\"-\"*50)\n",
    "    for folder, data in report.items():\n",
    "        print(f\"{folder:<30} {data['accuracy']:.2%}     {data['samples']:<10}\")\n",
    "    \n",
    "    print(\"\\nOverall Accuracy: {:.2%}\".format(total_correct/total_samples))\n",
    "    print(f\"Total Samples: {total_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "验证进度: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-53.7459,  -8.7001, -21.6833,  20.9177, -24.6376,   3.9168, -35.7238,\n",
      "           6.2989, -33.0160, -13.6443]], device='cuda:0') 3\n",
      "tensor([[-53.0259, -12.1218, -16.0565,  24.8588, -26.5871,   3.8469, -36.4938,\n",
      "           2.8232, -28.0511, -12.2536]], device='cuda:0') 3\n",
      "tensor([[-42.0783, -21.5153, -22.1611,  19.4667, -23.0932,  12.5842, -29.5226,\n",
      "          -9.6360, -23.6085,  -0.5249]], device='cuda:0') 3\n",
      "tensor([[-54.1972,   4.3171, -27.9862,  14.5558, -17.0534,   4.7830, -36.4898,\n",
      "          -7.8024, -25.0290, -11.2526]], device='cuda:0') 3\n",
      "pred_sum: 12 [3, 3, 3, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "验证进度: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "分析完成: 0/1 张图和为24 (占比 0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# -------------------- 数据集类（仅加载图像）-------------------\n",
    "class ImageOnlyDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        仅加载PNG图片，不处理任何标签\n",
    "        \"\"\"\n",
    "        self.image_paths = []\n",
    "        # 递归查找所有PNG文件\n",
    "        for dirpath, _, filenames in os.walk(root_dir):\n",
    "            # print(filenames)\n",
    "            for filename in filenames:\n",
    "                if filename.lower().endswith('1998.png'):\n",
    "                    self.image_paths.append(os.path.join(dirpath, filename))\n",
    "        \n",
    "        if not self.image_paths:\n",
    "            raise RuntimeError(f\"未找到PNG图片，请检查目录: {root_dir}\")\n",
    "\n",
    "        # 图像预处理\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))  # MNIST标准化\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx])\n",
    "        return {\n",
    "            \"image\": self.transform(img),  # [1, H, W]\n",
    "            \"path\": self.image_paths[idx]\n",
    "        }\n",
    "\n",
    "# -------------------- 验证器类 --------------------\n",
    "class SumValidator:\n",
    "    def __init__(self, mnist_model, device):\n",
    "        self.device = device\n",
    "        self.model = mnist_model.to(device).eval()\n",
    "        \n",
    "        # 子图预处理流程（保持与MNIST一致）\n",
    "        # self.subimage_transform = transforms.Compose([\n",
    "        #     transforms.Resize(28),\n",
    "        #     transforms.Normalize((0.1307,), (0.3081,))\n",
    "        # ])\n",
    "        self.subimage_transform = transforms.Compose([\n",
    "            transforms.Resize(28),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    def validate(self, dataloader):\n",
    "        total = 0\n",
    "        sum24_count = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc=\"验证进度\"):\n",
    "                full_images = batch[\"image\"].to(self.device)  # [B, 1, H, W]\n",
    "                \n",
    "                for img in full_images:\n",
    "                    # 分割图像\n",
    "                    sub_images = self._split_image(img)\n",
    "                    \n",
    "                    # 预测子图并计算和\n",
    "                    pred_sum,preds = self._predict_sum(sub_images)\n",
    "                    print(\"pred_sum:\",pred_sum,preds)\n",
    "                    \n",
    "                    # 统计结果\n",
    "                    total += 1\n",
    "                    sum24_count += int(pred_sum == 24)\n",
    "\n",
    "        accuracy = 100 * sum24_count / total if total > 0 else 0\n",
    "        print(f\"\\n分析完成: {sum24_count}/{total} 张图和为24 (占比 {accuracy:.2f}%)\")\n",
    "        return accuracy\n",
    "\n",
    "    def _split_image(self, img_tensor):\n",
    "        \"\"\"将图像分割为4个32x32子图\"\"\"\n",
    "        _, h, w = img_tensor.shape\n",
    "        if h < 64 or w < 64:\n",
    "            raise ValueError(f\"输入图像尺寸不足64x64，当前尺寸：{h}x{w}\")\n",
    "        sub_images = [\n",
    "            (\"Top-Left\", img_tensor[:, :32, :32]),\n",
    "            (\"Top-Right\", img_tensor[:, :32, 32:]),\n",
    "            (\"Bottom-Left\", img_tensor[:, 32:, :32]),\n",
    "            (\"Bottom-Right\", img_tensor[:, 32:, 32:])\n",
    "        ]\n",
    "        \n",
    "        # 创建画布\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # -------------------- 原始图像可视化 --------------------\n",
    "        # plt.subplot(2, 3, 1)  # 2行3列的第1个位置\n",
    "        # 转换为numpy并反标准化\n",
    "        # original_img = img_tensor.squeeze().cpu().numpy()\n",
    "        # original_img = original_img * 0.3081 + 0.1307  # 反标准化\n",
    "        # plt.imshow(original_img, cmap='gray')\n",
    "        # plt.title(\"Original Image (64x64)\")\n",
    "        # plt.axis('off')\n",
    "        \n",
    "        # # -------------------- 子图可视化 --------------------\n",
    "        # positions = [(0, 2), (0, 4), (1, 2), (1, 4)]  # 子图布局位置\n",
    "        # for idx, (title, sub_img) in enumerate(sub_images):\n",
    "        #     plt.subplot2grid((2, 5), positions[idx], colspan=2)\n",
    "        #     # 转换为numpy并反标准化\n",
    "        #     sub_img_np = sub_img.squeeze().cpu().numpy()\n",
    "        #     sub_img_np = sub_img_np * 0.3081 + 0.1307  # 反标准化\n",
    "        #     plt.imshow(sub_img_np, cmap='gray')\n",
    "        #     plt.title(title)\n",
    "        #     plt.axis('off')\n",
    "        \n",
    "        # plt.tight_layout()\n",
    "    \n",
    "        return [\n",
    "            img_tensor[:, :32, :32],   # 左上\n",
    "            img_tensor[:, :32, 32:],   # 右上\n",
    "            img_tensor[:, 32:, :32],   # 左下\n",
    "            img_tensor[:, 32:, 32:]    # 右下\n",
    "        ]\n",
    "\n",
    "    def _predict_sum(self, sub_images):\n",
    "        \"\"\"预测四个子图的数字并返回总和\"\"\"\n",
    "        sum_pred = 0\n",
    "        preds = []\n",
    "        for i, sub_img in enumerate(sub_images):\n",
    "            # 调整尺寸并添加批次维度\n",
    "            sub_img = sub_img.unsqueeze(0)  # [1, 1, 32, 32]\n",
    "            sub_img = torch.nn.functional.interpolate(sub_img, size=28)\n",
    "            \n",
    "            # 预处理\n",
    "            sub_img = self.subimage_transform(sub_img)\n",
    "            # 转换为NumPy并反标准化\n",
    "            img_np = sub_img.squeeze().cpu().numpy()\n",
    "            img_np = img_np * 0.3081 + 0.1307  # 反标准化\n",
    "\n",
    "            # 预测\n",
    "            output = self.model(sub_img)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob).item()\n",
    "            # pred = output.argmax(dim=1).item()\n",
    "            # 显示子图\n",
    "            # plt.subplot(1, 4, i+1)  # 1行4列，第i+1个位置\n",
    "            plt.imshow(img_np, cmap='gray')\n",
    "            # plt.title(f\"Sub-image {i+1} with pre label {pred}\")\n",
    "            plt.savefig(f\"/cpfs04/user/hanyujin/rule-gen/datasets/mnist-mnist-split/Sub-image_{i+1}.png\")\n",
    "            plt.axis('off')\n",
    "            preds.append(pred)\n",
    "            sum_pred += pred\n",
    "            print(output,pred)\n",
    "            \n",
    "        return sum_pred,preds\n",
    "\n",
    "\n",
    "# -------------------- 使用示例 --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置参数\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    data_dir = \"/cpfs04/user/hanyujin/rule-gen/datasets/mnist-mnist/images\"\n",
    "    \n",
    "    # 加载数据集\n",
    "    dataset = ImageOnlyDataset(data_dir)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # 加载MNIST模型\n",
    "    # mnist_model = MNIST_CNN()\n",
    "    # # 修改后的模型加载代码\n",
    "    # checkpoint = torch.load(\n",
    "    # \"/cpfs04/user/hanyujin/rule-gen/model_cpkt/mnist_cnn_best_v2.pth\",\n",
    "    # map_location=device\n",
    "    # )\n",
    "    # mnist_model.load_state_dict(checkpoint['state_dict'])  # 提取state_dict部分\n",
    "    mnist_model = mnist_model\n",
    "    \n",
    "    # 创建验证器\n",
    "    validator = SumValidator(mnist_model, device)\n",
    "    \n",
    "    # 执行验证\n",
    "    accuracy = validator.validate(dataloader)\n",
    "\n",
    "# Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------- 配置参数 --------------------\n",
    "DATA_DIR = \"/cpfs04/user/hanyujin/rule-gen/datasets/mnist-mnist-split\"\n",
    "MODEL_PATH = \"/cpfs04/user/hanyujin/rule-gen/model_cpkt/mnist_cnn_best.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------- 数据预处理 --------------------\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# -------------------- 预测函数 --------------------\n",
    "def predict_subimages():\n",
    "    # 加载模型\n",
    "    model = mnist_model\n",
    "    \n",
    "    # 读取子图文件\n",
    "    sub_images = []\n",
    "    for i in range(4):\n",
    "        img_path = os.path.join(DATA_DIR, f\"Sub-image_{i+1}.png\")\n",
    "        img = Image.open(img_path).convert('L')  # 强制转换为灰度图\n",
    "        sub_images.append(img)\n",
    "    \n",
    "    # 可视化与预测\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    with torch.no_grad():\n",
    "        for idx, img in enumerate(sub_images):\n",
    "            # 预处理\n",
    "            tensor_img = mnist_transform(img).unsqueeze(0).to(DEVICE)\n",
    "            \n",
    "            # 预测\n",
    "            output = model(tensor_img)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob).item()\n",
    "            confidence = prob[0][pred].item()\n",
    "            \n",
    "            # 可视化\n",
    "            plt.subplot(1, 4, idx+1)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.title(f\"Pred: {pred}\\nConf: {confidence:.2f}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"/cpfs04/user/hanyujin/rule-gen/prediction_result.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predict_subimages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:04<01:27,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 0.3813 | Val Loss: 0.0858 | Val Acc: 97.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:09<01:24,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Train Loss: 0.0899 | Val Loss: 0.0469 | Val Acc: 98.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:13<01:19,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Train Loss: 0.0679 | Val Loss: 0.0808 | Val Acc: 97.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:18<01:13,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Train Loss: 0.0560 | Val Loss: 0.0364 | Val Acc: 98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:22<01:08,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Train Loss: 0.0504 | Val Loss: 0.0312 | Val Acc: 99.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:27<01:02,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | Train Loss: 0.0443 | Val Loss: 0.0351 | Val Acc: 98.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:31<00:58,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 | Train Loss: 0.0399 | Val Loss: 0.0311 | Val Acc: 99.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:36<00:54,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 | Train Loss: 0.0395 | Val Loss: 0.0424 | Val Acc: 98.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:41<00:50,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 | Train Loss: 0.0269 | Val Loss: 0.0243 | Val Acc: 99.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:45<00:45,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 | Train Loss: 0.0226 | Val Loss: 0.0242 | Val Acc: 99.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:50<00:41,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 | Train Loss: 0.0222 | Val Loss: 0.0240 | Val Acc: 99.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:55<00:37,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 | Train Loss: 0.0201 | Val Loss: 0.0210 | Val Acc: 99.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:59<00:32,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 | Train Loss: 0.0192 | Val Loss: 0.0232 | Val Acc: 99.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:04<00:28,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 | Train Loss: 0.0197 | Val Loss: 0.0214 | Val Acc: 99.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [01:08<00:22,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 | Train Loss: 0.0185 | Val Loss: 0.0247 | Val Acc: 99.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [01:13<00:18,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 | Train Loss: 0.0169 | Val Loss: 0.0214 | Val Acc: 99.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:18<00:13,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 | Train Loss: 0.0168 | Val Loss: 0.0211 | Val Acc: 99.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [01:22<00:09,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 | Train Loss: 0.0163 | Val Loss: 0.0199 | Val Acc: 99.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [01:27<00:04,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 | Train Loss: 0.0156 | Val Loss: 0.0209 | Val Acc: 99.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:32<00:00,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 | Train Loss: 0.0161 | Val Loss: 0.0191 | Val Acc: 99.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Accuracy: 99.54%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import trange\n",
    "# -------------------- 配置参数 --------------------\n",
    "config = {\n",
    "    'batch_size': 128,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 20,\n",
    "    'num_workers': 4,\n",
    "    'save_dir': '/cpfs04/user/hanyujin/rule-gen/model_cpkt/',\n",
    "    'best_model_name': 'mnist_best_cnn_v2.pth'\n",
    "}\n",
    "\n",
    "# -------------------- 数据预处理 --------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),        # 数据增强\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# -------------------- 数据集类 --------------------\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, images_path, labels_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.images = self._load_images(images_path)\n",
    "        self.labels = self._load_labels(labels_path)\n",
    "\n",
    "    def _load_images(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            f.read(16)  # 跳过头部信息\n",
    "            data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            return data.reshape(-1, 28, 28)\n",
    "\n",
    "    def _load_labels(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            f.read(8)  # 跳过头部信息\n",
    "            return np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.fromarray(self.images[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, label\n",
    "\n",
    "# -------------------- 模型定义 --------------------\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# -------------------- 训练函数 --------------------\n",
    "def train_model():\n",
    "    # 创建保存目录\n",
    "    os.makedirs(config['save_dir'], exist_ok=True)\n",
    "    \n",
    "    # 设备设置\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = MNIST_CNN().to(device)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\n",
    "    \n",
    "    # 加载数据\n",
    "    train_set = MNISTDataset(\n",
    "        images_path='/cpfs04/user/hanyujin/rule-gen/datasets/MNIST/raw/train-images-idx3-ubyte',\n",
    "        labels_path='/cpfs04/user/hanyujin/rule-gen/datasets/MNIST/raw/train-labels-idx1-ubyte',\n",
    "        transform=train_transform\n",
    "    )\n",
    "    test_set = MNISTDataset(\n",
    "        images_path='/cpfs04/user/hanyujin/rule-gen/datasets/MNIST/raw/t10k-images-idx3-ubyte',\n",
    "        labels_path='/cpfs04/user/hanyujin/rule-gen/datasets/MNIST/raw/t10k-labels-idx1-ubyte',\n",
    "        transform=test_transform\n",
    "    )\n",
    "    \n",
    "    # 划分验证集\n",
    "    train_size = int(0.9 * len(train_set))\n",
    "    val_size = len(train_set) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        train_set, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    # 创建DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=config['num_workers']\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=config['num_workers']\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_set,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=config['num_workers']\n",
    "    )\n",
    "\n",
    "    # 初始化最佳准确率\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in trange(config['epochs']):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        # 计算指标\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = 100 * correct / total\n",
    "        \n",
    "        # 学习率调整\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \n",
    "                      os.path.join(config['save_dir'], config['best_model_name']))\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{config[\"epochs\"]} | '\n",
    "              f'Train Loss: {train_loss:.4f} | '\n",
    "              f'Val Loss: {val_loss:.4f} | '\n",
    "              f'Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "    # 最终测试\n",
    "    model.load_state_dict(torch.load(os.path.join(config['save_dir'], config['best_model_name'])))\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    print(f'\\nFinal Test Accuracy: {100 * correct / total:.2f}%')\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mnist_model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已生成 100/1000 张图像 | 当前组合: [0, 6, 6, 8]\n",
      "已生成 200/1000 张图像 | 当前组合: [9, 1, 1, 1]\n",
      "已生成 300/1000 张图像 | 当前组合: [4, 2, 6, 8]\n",
      "已生成 400/1000 张图像 | 当前组合: [6, 2, 2, 4]\n",
      "已生成 500/1000 张图像 | 当前组合: [3, 1, 7, 5]\n",
      "已生成 600/1000 张图像 | 当前组合: [3, 7, 1, 9]\n",
      "已生成 700/1000 张图像 | 当前组合: [7, 7, 5, 5]\n",
      "已生成 800/1000 张图像 | 当前组合: [0, 0, 6, 8]\n",
      "已生成 900/1000 张图像 | 当前组合: [1, 5, 3, 1]\n",
      "已生成 1000/1000 张图像 | 当前组合: [8, 8, 4, 2]\n",
      "数据集生成完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子保证可重复性\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 配置新数据保存路径\n",
    "output_dir = '/cpfs04/user/hanyujin/rule-gen/datasets/mnist-mnist-eo/images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 数据预处理流程\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, images_path, labels_path, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.labels_path = labels_path\n",
    "        self.transform = transform\n",
    "\n",
    "        # 加载图片和标签\n",
    "        self.images = self._load_images(self.images_path)\n",
    "        self.labels = self._load_labels(self.labels_path)\n",
    "\n",
    "    def _load_images(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            # Skip the first 16 bytes of the magic number and dimensions info\n",
    "            f.read(16)\n",
    "            # 读取所有图片数据\n",
    "            data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            images = data.reshape(-1, 28, 28)  # 图片是28x28的\n",
    "        return images\n",
    "\n",
    "    def _load_labels(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            # Skip the first 8 bytes of the magic number and number of labels\n",
    "            f.read(8)\n",
    "            labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = Image.fromarray(image)  # 将图片从numpy数组转为PIL图像\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 配置转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # 确保图像是28x28的\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 数据路径\n",
    "train_images_path = '/cpfs04/user/hanyujin/rule-gen/datasets/MNIST/raw/train-images-idx3-ubyte'\n",
    "train_labels_path = '/cpfs04/user/hanyujin/rule-gen/datasets/MNIST/raw/train-labels-idx1-ubyte'\n",
    "\n",
    "# 加载数据\n",
    "train_dataset = MNISTDataset(train_images_path, train_labels_path, transform=transform)\n",
    "\n",
    "# 按数字类别存储图像\n",
    "digit_images = defaultdict(list)\n",
    "for img, label in train_dataset:\n",
    "    digit_images[label.item()].append(img)\n",
    "\n",
    "# 生成1000张符合奇偶规则的图像\n",
    "for idx in range(1000):\n",
    "    while True:\n",
    "        # 随机选择奇偶类型\n",
    "        is_even = random.choice([True, False])\n",
    "        candidate_digits = [0, 2, 4, 6, 8] if is_even else [1, 3, 5, 7, 9]\n",
    "        \n",
    "        # 随机选择四个同奇偶数字\n",
    "        digits = [random.choice(candidate_digits) for _ in range(4)]\n",
    "        \n",
    "        # 验证所有数字都有可用图像\n",
    "        if all(len(digit_images[d]) > 10 for d in digits):  # 保证足够样本\n",
    "            break\n",
    "\n",
    "    # 选择四张不同图像\n",
    "    selected_images = [\n",
    "        random.choice(digit_images[digits[0]]),\n",
    "        random.choice(digit_images[digits[1]]),\n",
    "        random.choice(digit_images[digits[2]]),\n",
    "        random.choice(digit_images[digits[3]])\n",
    "    ]\n",
    "\n",
    "    # 图像预处理函数\n",
    "    def process_img(img_tensor):\n",
    "        pil_img = to_pil_image(img_tensor).resize((32, 32), Image.LANCZOS)\n",
    "        return pil_img.convert('L')\n",
    "\n",
    "    # 合成64x64图像\n",
    "    canvas = Image.new('L', (64, 64), color=0)  # 黑色背景\n",
    "    positions = [(0, 0), (32, 0), (0, 32), (32, 32)]\n",
    "    \n",
    "    for img_tensor, pos in zip(selected_images, positions):\n",
    "        img = process_img(img_tensor)\n",
    "        canvas.paste(img, pos)\n",
    "\n",
    "    # 保存图像并记录元数据\n",
    "    filename = f\"eo_{'even' if is_even else 'odd'}_{idx:04d}.png\"\n",
    "    canvas.save(os.path.join(output_dir, filename))\n",
    "\n",
    "    # 进度显示\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        print(f'已生成 {idx + 1}/1000 张图像 | 当前组合: {digits}')\n",
    "\n",
    "print(\"数据集生成完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已生成 100/1000 张图像 | 当前序列: [1, 2, 3, 4]\n",
      "已生成 200/1000 张图像 | 当前序列: [3, 4, 5, 6]\n",
      "已生成 300/1000 张图像 | 当前序列: [3, 4, 5, 6]\n",
      "已生成 400/1000 张图像 | 当前序列: [1, 2, 3, 4]\n",
      "已生成 500/1000 张图像 | 当前序列: [6, 7, 8, 9]\n",
      "已生成 600/1000 张图像 | 当前序列: [0, 1, 2, 3]\n",
      "已生成 700/1000 张图像 | 当前序列: [6, 7, 8, 9]\n",
      "已生成 800/1000 张图像 | 当前序列: [1, 2, 3, 4]\n",
      "已生成 900/1000 张图像 | 当前序列: [1, 2, 3, 4]\n",
      "已生成 1000/1000 张图像 | 当前序列: [2, 3, 4, 5]\n",
      "等差序列数据集生成完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子保证可重复性\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 配置新数据保存路径\n",
    "output_dir = '/cpfs04/user/hanyujin/rule-gen/datasets/mnist-mnist-seq/images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 数据预处理流程\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, images_path, labels_path, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.labels_path = labels_path\n",
    "        self.transform = transform\n",
    "\n",
    "        # 加载图片和标签\n",
    "        self.images = self._load_images(self.images_path)\n",
    "        self.labels = self._load_labels(self.labels_path)\n",
    "\n",
    "    def _load_images(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            # Skip the first 16 bytes of the magic number and dimensions info\n",
    "            f.read(16)\n",
    "            # 读取所有图片数据\n",
    "            data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            images = data.reshape(-1, 28, 28)  # 图片是28x28的\n",
    "        return images\n",
    "\n",
    "    def _load_labels(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            # Skip the first 8 bytes of the magic number and number of labels\n",
    "            f.read(8)\n",
    "            labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = Image.fromarray(image)  # 将图片从numpy数组转为PIL图像\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 配置转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # 确保图像是28x28的\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 数据路径\n",
    "train_images_path = '/cpfs04/user/hanyujin/rule-gen/datasets/MNIST/raw/train-images-idx3-ubyte'\n",
    "train_labels_path = '/cpfs04/user/hanyujin/rule-gen/datasets/MNIST/raw/train-labels-idx1-ubyte'\n",
    "\n",
    "# 加载数据\n",
    "train_dataset = MNISTDataset(train_images_path, train_labels_path, transform=transform)\n",
    "\n",
    "\n",
    "# 按数字类别存储图像\n",
    "digit_images = defaultdict(list)\n",
    "for img, label in train_dataset:\n",
    "    digit_images[label.item()].append(img)\n",
    "\n",
    "# 生成1000张等差序列图像\n",
    "valid_sequences = []\n",
    "for start in range(7):  # 允许的起始数字范围(0-6)\n",
    "    seq = [start, start+1, start+2, start+3]\n",
    "    if all(d in digit_images and len(digit_images[d]) > 10 for d in seq):\n",
    "        valid_sequences.append(seq)\n",
    "\n",
    "total_generated = 0\n",
    "while total_generated < 1000:\n",
    "    # 随机选择有效序列\n",
    "    sequence = random.choice(valid_sequences)\n",
    "    \n",
    "    try:\n",
    "        # 选择四张不同图像\n",
    "        selected_images = [\n",
    "            random.choice(digit_images[sequence[0]]),\n",
    "            random.choice(digit_images[sequence[1]]),\n",
    "            random.choice(digit_images[sequence[2]]),\n",
    "            random.choice(digit_images[sequence[3]])\n",
    "        ]\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "    # 图像预处理函数\n",
    "    def process_img(img_tensor):\n",
    "        pil_img = to_pil_image(img_tensor).resize((32, 32), Image.LANCZOS)\n",
    "        return pil_img.convert('L')\n",
    "\n",
    "    # 合成64x64图像\n",
    "    canvas = Image.new('L', (64, 64), color=0)  # 黑色背景\n",
    "    positions = [(0, 0), (32, 0), (0, 32), (32, 32)]\n",
    "    \n",
    "    for img_tensor, pos in zip(selected_images, positions):\n",
    "        img = process_img(img_tensor)\n",
    "        canvas.paste(img, pos)\n",
    "\n",
    "    # 保存图像并记录元数据\n",
    "    filename = f\"seq_{sequence[0]}-{sequence[3]}_{total_generated:04d}.png\"\n",
    "    canvas.save(os.path.join(output_dir, filename))\n",
    "    \n",
    "    total_generated += 1\n",
    "\n",
    "    # 进度显示\n",
    "    if total_generated % 100 == 0:\n",
    "        print(f'已生成 {total_generated}/1000 张图像 | 当前序列: {sequence}')\n",
    "\n",
    "print(\"等差序列数据集生成完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yjenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
